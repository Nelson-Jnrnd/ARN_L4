{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "MLP_from_raw_data.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic-cqm0tbUc3"
   },
   "source": [
    "# Multilayer Perceptron from raw data\n",
    "This notebook will guide you through the use of the `keras` package to train a multilayer perceptron for handwritten digits classification. You are going to use the `mnist` dataset from LeCun et al. 1998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND1Cf9lXbUc6"
   },
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pvq0DhLtbUdE"
   },
   "source": [
    "%pip install tensorflow --upgrade\n",
    "%pip install keras --upgrade\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics as me\n",
    "from tensorflow.keras.backend import clear_session\n",
    "%matplotlib inline"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\NelsonWork\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\nelsonwork\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\NelsonWork\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy0wRnm2bUde"
   },
   "source": [
    "## Using raw data to train a MLP\n",
    "First load the `mnist` dataset and normalize it to be in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8CKuJwcibUdi",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "outputId": "62b6c3c9-af3b-4769-c557-cd6c74afcefe"
   },
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "n_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01XwVeDNbUdv"
   },
   "source": [
    "Create the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def test_hypers(neurons, drops, batch_sizes, optims, optimNames):\n",
    "    for n_neurons in neurons:\n",
    "        for drop in drops:\n",
    "            for batch_size in batch_sizes:\n",
    "                for i_o, optim in enumerate(optims):\n",
    "                    n_epoch = 20\n",
    "                    clear_session()\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(n_neurons, input_shape=(784,), activation='relu'))\n",
    "                    if drop > 0:\n",
    "                        model.add(Dropout(drop))\n",
    "                    model.add(Dense(n_classes, activation='softmax'))\n",
    "                    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "                    history = model.fit(X_train, Y_train,\n",
    "                                    batch_size=batch_size, epochs=n_epoch,\n",
    "                                    verbose=1, validation_data=(X_test, Y_test))\n",
    "                    plot_graph(history, optimNames[i_o], batch_size, n_epoch, n_neurons, drop)\n",
    "                    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "                    print('Test score:', score[0])\n",
    "                    print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.8421 - accuracy: 0.7365 - val_loss: 0.5068 - val_accuracy: 0.8506\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4707 - accuracy: 0.8607 - val_loss: 0.4348 - val_accuracy: 0.8723\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4220 - accuracy: 0.8769 - val_loss: 0.4000 - val_accuracy: 0.8843\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8848 - val_loss: 0.3880 - val_accuracy: 0.8881\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3833 - accuracy: 0.8883 - val_loss: 0.3840 - val_accuracy: 0.8880\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8921 - val_loss: 0.3755 - val_accuracy: 0.8930\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8924 - val_loss: 0.3720 - val_accuracy: 0.8918\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3631 - accuracy: 0.8940 - val_loss: 0.3724 - val_accuracy: 0.8924\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8953 - val_loss: 0.3696 - val_accuracy: 0.8936\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3558 - accuracy: 0.8970 - val_loss: 0.3660 - val_accuracy: 0.8972\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3528 - accuracy: 0.8991 - val_loss: 0.3711 - val_accuracy: 0.8922\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3504 - accuracy: 0.8985 - val_loss: 0.3682 - val_accuracy: 0.8956\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3485 - accuracy: 0.8987 - val_loss: 0.3647 - val_accuracy: 0.8985\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3469 - accuracy: 0.8995 - val_loss: 0.3697 - val_accuracy: 0.8933\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8993 - val_loss: 0.3592 - val_accuracy: 0.8989\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3437 - accuracy: 0.9006 - val_loss: 0.3593 - val_accuracy: 0.8973\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3427 - accuracy: 0.9014 - val_loss: 0.3588 - val_accuracy: 0.8997\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3420 - accuracy: 0.9015 - val_loss: 0.3654 - val_accuracy: 0.8983\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.9013 - val_loss: 0.3589 - val_accuracy: 0.9006\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.9018 - val_loss: 0.3644 - val_accuracy: 0.8961\n",
      "Test score: 0.364402174949646\n",
      "Test accuracy: 0.8960999846458435\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.0187 - accuracy: 0.6770 - val_loss: 0.6358 - val_accuracy: 0.8049\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5942 - accuracy: 0.8169 - val_loss: 0.5335 - val_accuracy: 0.8409\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5142 - accuracy: 0.8482 - val_loss: 0.4768 - val_accuracy: 0.8616\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4703 - accuracy: 0.8647 - val_loss: 0.4523 - val_accuracy: 0.8686\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.8721 - val_loss: 0.4336 - val_accuracy: 0.8746\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4296 - accuracy: 0.8783 - val_loss: 0.4286 - val_accuracy: 0.8771\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4187 - accuracy: 0.8828 - val_loss: 0.4173 - val_accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4102 - accuracy: 0.8850 - val_loss: 0.4143 - val_accuracy: 0.8865\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8877 - val_loss: 0.4067 - val_accuracy: 0.8877\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3964 - accuracy: 0.8900 - val_loss: 0.4038 - val_accuracy: 0.8868\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8908 - val_loss: 0.4004 - val_accuracy: 0.8881\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3855 - accuracy: 0.8928 - val_loss: 0.3914 - val_accuracy: 0.8902\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3809 - accuracy: 0.8938 - val_loss: 0.3860 - val_accuracy: 0.8906\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3762 - accuracy: 0.8942 - val_loss: 0.3855 - val_accuracy: 0.8888\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8952 - val_loss: 0.3782 - val_accuracy: 0.8916\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3677 - accuracy: 0.8969 - val_loss: 0.3743 - val_accuracy: 0.8913\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3629 - accuracy: 0.8978 - val_loss: 0.3780 - val_accuracy: 0.8918\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3594 - accuracy: 0.8998 - val_loss: 0.3722 - val_accuracy: 0.8927\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3561 - accuracy: 0.8996 - val_loss: 0.3701 - val_accuracy: 0.8929\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3526 - accuracy: 0.9005 - val_loss: 0.3673 - val_accuracy: 0.8934\n",
      "Test score: 0.367270827293396\n",
      "Test accuracy: 0.8934000134468079\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.6241 - accuracy: 0.4575 - val_loss: 1.1450 - val_accuracy: 0.6336\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.9269 - accuracy: 0.7218 - val_loss: 0.7679 - val_accuracy: 0.7678\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.7088 - accuracy: 0.7816 - val_loss: 0.6443 - val_accuracy: 0.7986\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.6221 - accuracy: 0.8082 - val_loss: 0.5804 - val_accuracy: 0.8216\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.8250 - val_loss: 0.5409 - val_accuracy: 0.8342\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.8359 - val_loss: 0.5165 - val_accuracy: 0.8440\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5168 - accuracy: 0.8436 - val_loss: 0.4934 - val_accuracy: 0.8519\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4955 - accuracy: 0.8516 - val_loss: 0.4767 - val_accuracy: 0.8551\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4769 - accuracy: 0.8582 - val_loss: 0.4592 - val_accuracy: 0.8627\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4612 - accuracy: 0.8646 - val_loss: 0.4456 - val_accuracy: 0.8644\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4488 - accuracy: 0.8690 - val_loss: 0.4362 - val_accuracy: 0.8694\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4385 - accuracy: 0.8723 - val_loss: 0.4268 - val_accuracy: 0.8717\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4302 - accuracy: 0.8750 - val_loss: 0.4221 - val_accuracy: 0.8717\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.8770 - val_loss: 0.4144 - val_accuracy: 0.8761\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4174 - accuracy: 0.8790 - val_loss: 0.4082 - val_accuracy: 0.8778\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4125 - accuracy: 0.8815 - val_loss: 0.4046 - val_accuracy: 0.8785\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4080 - accuracy: 0.8825 - val_loss: 0.3996 - val_accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8832 - val_loss: 0.3983 - val_accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4007 - accuracy: 0.8845 - val_loss: 0.3976 - val_accuracy: 0.8830\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3976 - accuracy: 0.8853 - val_loss: 0.3918 - val_accuracy: 0.8831\n",
      "Test score: 0.39177781343460083\n",
      "Test accuracy: 0.8830999732017517\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.2364 - accuracy: 0.6042 - val_loss: 0.7670 - val_accuracy: 0.7787\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6661 - accuracy: 0.8065 - val_loss: 0.5756 - val_accuracy: 0.8380\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.8440 - val_loss: 0.5147 - val_accuracy: 0.8545\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.8573 - val_loss: 0.4831 - val_accuracy: 0.8627\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.8649 - val_loss: 0.4674 - val_accuracy: 0.8673\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8691 - val_loss: 0.4520 - val_accuracy: 0.8732\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.8720 - val_loss: 0.4450 - val_accuracy: 0.8748\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.8740 - val_loss: 0.4434 - val_accuracy: 0.8759\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8760 - val_loss: 0.4378 - val_accuracy: 0.8748\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8768 - val_loss: 0.4333 - val_accuracy: 0.8791\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.8775 - val_loss: 0.4281 - val_accuracy: 0.8793\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8787 - val_loss: 0.4297 - val_accuracy: 0.8809\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8801 - val_loss: 0.4262 - val_accuracy: 0.8823\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4239 - accuracy: 0.8809 - val_loss: 0.4254 - val_accuracy: 0.8823\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4212 - accuracy: 0.8808 - val_loss: 0.4232 - val_accuracy: 0.8831\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4183 - accuracy: 0.8824 - val_loss: 0.4210 - val_accuracy: 0.8830\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4159 - accuracy: 0.8827 - val_loss: 0.4218 - val_accuracy: 0.8843\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4138 - accuracy: 0.8831 - val_loss: 0.4230 - val_accuracy: 0.8809\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8837 - val_loss: 0.4187 - val_accuracy: 0.8835\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8838 - val_loss: 0.4193 - val_accuracy: 0.8815\n",
      "Test score: 0.4192671775817871\n",
      "Test accuracy: 0.8815000057220459\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.7936 - accuracy: 0.7581 - val_loss: 0.5685 - val_accuracy: 0.8397\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.8464 - val_loss: 0.4902 - val_accuracy: 0.8641\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.8661 - val_loss: 0.4489 - val_accuracy: 0.8783\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4457 - accuracy: 0.8766 - val_loss: 0.4241 - val_accuracy: 0.8854\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.8833 - val_loss: 0.4103 - val_accuracy: 0.8875\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.8870 - val_loss: 0.3984 - val_accuracy: 0.8911\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8902 - val_loss: 0.3884 - val_accuracy: 0.8951\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3860 - accuracy: 0.8919 - val_loss: 0.3828 - val_accuracy: 0.8954\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3793 - accuracy: 0.8933 - val_loss: 0.3782 - val_accuracy: 0.8947\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3735 - accuracy: 0.8956 - val_loss: 0.3727 - val_accuracy: 0.8969\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8960 - val_loss: 0.3697 - val_accuracy: 0.8978\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8976 - val_loss: 0.3709 - val_accuracy: 0.8960\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8985 - val_loss: 0.3653 - val_accuracy: 0.8995\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8990 - val_loss: 0.3692 - val_accuracy: 0.8955\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8997 - val_loss: 0.3622 - val_accuracy: 0.8972\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.9004 - val_loss: 0.3700 - val_accuracy: 0.8955\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3527 - accuracy: 0.9010 - val_loss: 0.3592 - val_accuracy: 0.8986\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.9011 - val_loss: 0.3588 - val_accuracy: 0.8994\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.9013 - val_loss: 0.3554 - val_accuracy: 0.8997\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.9025 - val_loss: 0.3589 - val_accuracy: 0.8992\n",
      "Test score: 0.3588847517967224\n",
      "Test accuracy: 0.8992000222206116\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 2.1213 - accuracy: 0.1983 - val_loss: 1.9103 - val_accuracy: 0.3003\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.7081 - accuracy: 0.4062 - val_loss: 1.4688 - val_accuracy: 0.4929\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.2432 - accuracy: 0.6029 - val_loss: 1.0102 - val_accuracy: 0.7173\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.9056 - accuracy: 0.7393 - val_loss: 0.7986 - val_accuracy: 0.7644\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.7697 - accuracy: 0.7701 - val_loss: 0.7139 - val_accuracy: 0.7863\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.7057 - accuracy: 0.7887 - val_loss: 0.6654 - val_accuracy: 0.8032\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6659 - accuracy: 0.8013 - val_loss: 0.6333 - val_accuracy: 0.8174\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6374 - accuracy: 0.8117 - val_loss: 0.6087 - val_accuracy: 0.8235\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.8186 - val_loss: 0.5890 - val_accuracy: 0.8309\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.8247 - val_loss: 0.5741 - val_accuracy: 0.8336\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.8293 - val_loss: 0.5585 - val_accuracy: 0.8384\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.8341 - val_loss: 0.5452 - val_accuracy: 0.8409\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.8377 - val_loss: 0.5351 - val_accuracy: 0.8442\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.8403 - val_loss: 0.5261 - val_accuracy: 0.8468\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.8435 - val_loss: 0.5170 - val_accuracy: 0.8502\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5281 - accuracy: 0.8456 - val_loss: 0.5106 - val_accuracy: 0.8523\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5208 - accuracy: 0.8483 - val_loss: 0.5039 - val_accuracy: 0.8542\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5141 - accuracy: 0.8501 - val_loss: 0.4987 - val_accuracy: 0.8556\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.8513 - val_loss: 0.4930 - val_accuracy: 0.8577\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.8533 - val_loss: 0.4880 - val_accuracy: 0.8577\n",
      "Test score: 0.4880007803440094\n",
      "Test accuracy: 0.857699990272522\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.5115 - accuracy: 0.4604 - val_loss: 0.9855 - val_accuracy: 0.7437\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.7687 - accuracy: 0.7949 - val_loss: 0.6153 - val_accuracy: 0.8292\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.8407 - val_loss: 0.5211 - val_accuracy: 0.8543\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.8591 - val_loss: 0.4817 - val_accuracy: 0.8672\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8677 - val_loss: 0.4600 - val_accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4512 - accuracy: 0.8735 - val_loss: 0.4462 - val_accuracy: 0.8761\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.8777 - val_loss: 0.4340 - val_accuracy: 0.8806\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4262 - accuracy: 0.8810 - val_loss: 0.4258 - val_accuracy: 0.8829\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8832 - val_loss: 0.4201 - val_accuracy: 0.8833\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8859 - val_loss: 0.4168 - val_accuracy: 0.8845\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4046 - accuracy: 0.8874 - val_loss: 0.4107 - val_accuracy: 0.8878\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.8891 - val_loss: 0.4044 - val_accuracy: 0.8910\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3943 - accuracy: 0.8903 - val_loss: 0.4056 - val_accuracy: 0.8890\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3905 - accuracy: 0.8917 - val_loss: 0.3976 - val_accuracy: 0.8925\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3864 - accuracy: 0.8928 - val_loss: 0.3941 - val_accuracy: 0.8911\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3827 - accuracy: 0.8947 - val_loss: 0.3914 - val_accuracy: 0.8918\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3793 - accuracy: 0.8952 - val_loss: 0.3898 - val_accuracy: 0.8915\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3765 - accuracy: 0.8959 - val_loss: 0.3860 - val_accuracy: 0.8934\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8968 - val_loss: 0.3839 - val_accuracy: 0.8954\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.3706 - accuracy: 0.8984 - val_loss: 0.3804 - val_accuracy: 0.8948\n",
      "Test score: 0.38044992089271545\n",
      "Test accuracy: 0.8948000073432922\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.1306 - accuracy: 0.6431 - val_loss: 0.7542 - val_accuracy: 0.7879\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6678 - accuracy: 0.8070 - val_loss: 0.5865 - val_accuracy: 0.8372\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5663 - accuracy: 0.8402 - val_loss: 0.5320 - val_accuracy: 0.8459\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5243 - accuracy: 0.8490 - val_loss: 0.5050 - val_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.8548 - val_loss: 0.4936 - val_accuracy: 0.8568\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.8583 - val_loss: 0.4846 - val_accuracy: 0.8565\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.8609 - val_loss: 0.4786 - val_accuracy: 0.8614\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4749 - accuracy: 0.8630 - val_loss: 0.4720 - val_accuracy: 0.8634\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4683 - accuracy: 0.8650 - val_loss: 0.4700 - val_accuracy: 0.8643\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.8669 - val_loss: 0.4667 - val_accuracy: 0.8638\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.8680 - val_loss: 0.4632 - val_accuracy: 0.8658\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.8686 - val_loss: 0.4629 - val_accuracy: 0.8677\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4531 - accuracy: 0.8705 - val_loss: 0.4585 - val_accuracy: 0.8675\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.8706 - val_loss: 0.4592 - val_accuracy: 0.8673\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.8703 - val_loss: 0.4561 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8720 - val_loss: 0.4567 - val_accuracy: 0.8676\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8722 - val_loss: 0.4521 - val_accuracy: 0.8694\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8730 - val_loss: 0.4527 - val_accuracy: 0.8703\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8729 - val_loss: 0.4500 - val_accuracy: 0.8701\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8735 - val_loss: 0.4509 - val_accuracy: 0.8707\n",
      "Test score: 0.45092689990997314\n",
      "Test accuracy: 0.8707000017166138\n",
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.0363 - accuracy: 0.3247 - val_loss: 1.8169 - val_accuracy: 0.4271\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.6558 - accuracy: 0.4769 - val_loss: 1.4491 - val_accuracy: 0.5623\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.2981 - accuracy: 0.6292 - val_loss: 1.1052 - val_accuracy: 0.7140\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0137 - accuracy: 0.7292 - val_loss: 0.8837 - val_accuracy: 0.7594\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.8460 - accuracy: 0.7610 - val_loss: 0.7630 - val_accuracy: 0.7801\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.7502 - accuracy: 0.7806 - val_loss: 0.6890 - val_accuracy: 0.7950\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6881 - accuracy: 0.7955 - val_loss: 0.6398 - val_accuracy: 0.8083\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6439 - accuracy: 0.8079 - val_loss: 0.6023 - val_accuracy: 0.8203\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.8180 - val_loss: 0.5738 - val_accuracy: 0.8298\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.8271 - val_loss: 0.5518 - val_accuracy: 0.8371\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5628 - accuracy: 0.8345 - val_loss: 0.5341 - val_accuracy: 0.8412\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.8400 - val_loss: 0.5184 - val_accuracy: 0.8469\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.8450 - val_loss: 0.5059 - val_accuracy: 0.8504\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5185 - accuracy: 0.8502 - val_loss: 0.4954 - val_accuracy: 0.8526\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.8532 - val_loss: 0.4864 - val_accuracy: 0.8552\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.8564 - val_loss: 0.4780 - val_accuracy: 0.8580\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.8593 - val_loss: 0.4717 - val_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.8610 - val_loss: 0.4662 - val_accuracy: 0.8605\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8631 - val_loss: 0.4594 - val_accuracy: 0.8629\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.8651 - val_loss: 0.4547 - val_accuracy: 0.8651\n",
      "Test score: 0.45470479130744934\n",
      "Test accuracy: 0.8651000261306763\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4703 - accuracy: 0.4377 - val_loss: 0.8769 - val_accuracy: 0.7728\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2717 - accuracy: 0.5084 - val_loss: 0.7908 - val_accuracy: 0.7900\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2292 - accuracy: 0.5251 - val_loss: 0.7456 - val_accuracy: 0.8088\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.2121 - accuracy: 0.5345 - val_loss: 0.6992 - val_accuracy: 0.8214\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1930 - accuracy: 0.5442 - val_loss: 0.6907 - val_accuracy: 0.8305\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1810 - accuracy: 0.5502 - val_loss: 0.6737 - val_accuracy: 0.8406\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1822 - accuracy: 0.5481 - val_loss: 0.6612 - val_accuracy: 0.8377\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1769 - accuracy: 0.5494 - val_loss: 0.6695 - val_accuracy: 0.8338\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1730 - accuracy: 0.5533 - val_loss: 0.6828 - val_accuracy: 0.8310\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1683 - accuracy: 0.5543 - val_loss: 0.6669 - val_accuracy: 0.8437\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1716 - accuracy: 0.5561 - val_loss: 0.6447 - val_accuracy: 0.8474\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1553 - accuracy: 0.5658 - val_loss: 0.6635 - val_accuracy: 0.8406\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1584 - accuracy: 0.5699 - val_loss: 0.6280 - val_accuracy: 0.8523\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1581 - accuracy: 0.5693 - val_loss: 0.6360 - val_accuracy: 0.8472\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1662 - accuracy: 0.5656 - val_loss: 0.6259 - val_accuracy: 0.8527\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1620 - accuracy: 0.5684 - val_loss: 0.6277 - val_accuracy: 0.8528\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1527 - accuracy: 0.5715 - val_loss: 0.6343 - val_accuracy: 0.8452\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1543 - accuracy: 0.5725 - val_loss: 0.6270 - val_accuracy: 0.8505\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1547 - accuracy: 0.5703 - val_loss: 0.6520 - val_accuracy: 0.8430\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.1440 - accuracy: 0.5750 - val_loss: 0.6247 - val_accuracy: 0.8534\n",
      "Test score: 0.6247326731681824\n",
      "Test accuracy: 0.8533999919891357\n",
      "Epoch 1/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.6183 - accuracy: 0.4035 - val_loss: 1.1555 - val_accuracy: 0.6848\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.5147 - accuracy: 0.4525 - val_loss: 1.1137 - val_accuracy: 0.7050\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.5028 - accuracy: 0.4606 - val_loss: 1.0870 - val_accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4937 - accuracy: 0.4632 - val_loss: 1.0757 - val_accuracy: 0.7128\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4921 - accuracy: 0.4649 - val_loss: 1.0743 - val_accuracy: 0.7110\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4865 - accuracy: 0.4661 - val_loss: 1.0578 - val_accuracy: 0.7152\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4798 - accuracy: 0.4709 - val_loss: 1.0632 - val_accuracy: 0.7165\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4743 - accuracy: 0.4729 - val_loss: 1.0622 - val_accuracy: 0.7039\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4798 - accuracy: 0.4703 - val_loss: 1.0507 - val_accuracy: 0.7150\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4760 - accuracy: 0.4720 - val_loss: 1.0489 - val_accuracy: 0.7165\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4727 - accuracy: 0.4730 - val_loss: 1.0549 - val_accuracy: 0.7204\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4741 - accuracy: 0.4721 - val_loss: 1.0631 - val_accuracy: 0.7201\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4727 - accuracy: 0.4732 - val_loss: 1.0443 - val_accuracy: 0.7202\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4707 - accuracy: 0.4755 - val_loss: 1.0519 - val_accuracy: 0.7157\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4749 - accuracy: 0.4739 - val_loss: 1.0476 - val_accuracy: 0.7201\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4651 - accuracy: 0.4805 - val_loss: 1.0533 - val_accuracy: 0.7123\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.4717 - accuracy: 0.4785 - val_loss: 1.0404 - val_accuracy: 0.7177\n",
      "Epoch 18/20\n",
      "801/938 [========================>.....] - ETA: 0s - loss: 1.4685 - accuracy: 0.4821"
     ]
    }
   ],
   "source": [
    "test_hypers([5, 50, 100, 300], [-1, 0.3, 0.5], [64, 128, 256], [RMSprop(), Adam(), SGD()], ['RMSprop', 'Adam', 'SGD'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def plot_graph(history, optimName, batch_size, n_epoch, n_neurons, drop):\n",
    "    pl.clf()\n",
    "    pl.plot(history.history['loss'], label='Training')\n",
    "    pl.plot(history.history['val_loss'], label='Testing')\n",
    "    pl.ylabel('loss')\n",
    "    pl.xlabel('Number of epochs')\n",
    "    pl.title(optimName+' Batch size:'+str(batch_size)+' Nb epochs:'+str(n_epoch)+' Nb neurons:'+str(n_neurons)+' Dropout:'+ ('None' if drop < 0 else str(drop)))\n",
    "    pl.legend()\n",
    "    pl.grid()\n",
    "    pl.savefig('../output/' + optimName+'_Batch_size'+str(batch_size)+' Nb_epochs'+str(n_epoch)+' Nb_neurons'+str(n_neurons)+'_Dropout_'+ ('None' if drop < 0 else str(drop)) + '.png', dpi=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DNgzrBJEbUd0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "f34f82a1-cd6b-474f-8186-a0c61f81a08c"
   },
   "source": [
    "n_neurons = 50\n",
    "drop = 0.5\n",
    "model = Sequential()\n",
    "model.add(Dense(n_neurons, input_shape=(784,), activation='relu'))\n",
    "if drop > 0:\n",
    "    model.add(Dropout(drop))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 50)                39250     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Peiq9GR2bUeN"
   },
   "source": [
    "Define some constants and train the MLP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NBt-ReqIbUeR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "outputId": "b1e07312-0ddd-4a6c-a52d-c762dda98b1b"
   },
   "source": [
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=n_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.7197 - accuracy: 0.7794 - val_loss: 0.2767 - val_accuracy: 0.9201\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4158 - accuracy: 0.8775 - val_loss: 0.2256 - val_accuracy: 0.9357\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3638 - accuracy: 0.8936 - val_loss: 0.1957 - val_accuracy: 0.9429\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.3358 - accuracy: 0.9012 - val_loss: 0.1809 - val_accuracy: 0.9460\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3158 - accuracy: 0.9067 - val_loss: 0.1709 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3054 - accuracy: 0.9094 - val_loss: 0.1660 - val_accuracy: 0.9508\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2964 - accuracy: 0.9123 - val_loss: 0.1568 - val_accuracy: 0.9529\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2817 - accuracy: 0.9161 - val_loss: 0.1507 - val_accuracy: 0.9556\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2758 - accuracy: 0.9172 - val_loss: 0.1486 - val_accuracy: 0.9562\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2710 - accuracy: 0.9185 - val_loss: 0.1444 - val_accuracy: 0.9581\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2605 - accuracy: 0.9209 - val_loss: 0.1410 - val_accuracy: 0.9604\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2607 - accuracy: 0.9208 - val_loss: 0.1411 - val_accuracy: 0.9597\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2548 - accuracy: 0.9218 - val_loss: 0.1394 - val_accuracy: 0.9593\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2501 - accuracy: 0.9238 - val_loss: 0.1424 - val_accuracy: 0.9599\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2502 - accuracy: 0.9229 - val_loss: 0.1367 - val_accuracy: 0.9593\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2441 - accuracy: 0.9248 - val_loss: 0.1370 - val_accuracy: 0.9613\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2423 - accuracy: 0.9245 - val_loss: 0.1379 - val_accuracy: 0.9594\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.2360 - accuracy: 0.9269 - val_loss: 0.1353 - val_accuracy: 0.9626\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2374 - accuracy: 0.9270 - val_loss: 0.1342 - val_accuracy: 0.9620\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9272 - val_loss: 0.1335 - val_accuracy: 0.9628\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u_zpHr5bUeb"
   },
   "source": [
    "Show the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PHXi21E1bUef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "outputId": "b153b1ab-4795-4704-b1a3-f28d4d636043"
   },
   "source": [
    "pl.plot(history.history['loss'], label='Training')\n",
    "pl.plot(history.history['val_loss'], label='Testing')\n",
    "pl.ylabel('loss')\n",
    "pl.xlabel('Number of epochs')\n",
    "pl.title('Batch size:'+str(batch_size)+' Nb epochs:'+str(n_epoch)+' Nb neurons:'+str(n_neurons)+' Dropout:'+ ('None' if drop < 0 else str(drop)) )\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.13354282081127167\n",
      "Test accuracy: 0.9628000259399414\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLuFK6MobUet"
   },
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PAjwjjrjbUex",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "outputId": "c96b6cf1-3bb9-4056-a6ec-0f20921828c3"
   },
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "me.confusion_matrix(y_test, pred)"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 966,    0,    2,    1,    0,    3,    5,    1,    2,    0],\n       [   0, 1113,    5,    2,    0,    0,    3,    1,   11,    0],\n       [   2,    0,  999,    4,    5,    1,    2,    9,   10,    0],\n       [   0,    0,   13,  971,    1,    7,    0,   10,    6,    2],\n       [   1,    0,    5,    0,  950,    0,   10,    2,    3,   11],\n       [   4,    1,    1,   11,    5,  846,    9,    4,    8,    3],\n       [   9,    3,    2,    1,    4,    7,  927,    0,    5,    0],\n       [   2,    8,   11,    8,    4,    0,    0,  990,    0,    5],\n       [   6,    3,    5,    8,    7,    9,    6,    8,  920,    2],\n       [   7,    8,    0,   12,   21,    5,    0,    8,    2,  946]],\n      dtype=int64)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}